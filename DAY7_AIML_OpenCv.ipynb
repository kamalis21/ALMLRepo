{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ff5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "#lk=dict()\n",
    "mask=np.random.randint(0,255,(100,4))\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f249aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 640, 3)\n",
      "(426, 640, 3)\n",
      "(426, 640, 3)\n",
      "(426, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function VideoCapture.release>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid=cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "#lk=dict()\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "mask2=np.zeros_like(frame1)\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "vid.release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a778473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 640, 3)\n",
      "(426, 640, 3)\n",
      "(426, 640, 3)\n",
      "(426, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function VideoCapture.release>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "#lk=dict()\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "mask2=np.zeros_like(frame1)\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "vid.release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00bd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    points2, status, err = cv2.calcOpticalFlowPyrLK(gray1, gray, points1, None, winSize=(15, 15), maxLevel=2,\n",
    "                                                   criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    newpts = points2[status == 1]\n",
    "    oldpts = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(newpts, oldpts)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "    elif key == ord('n'):  # Press 'n' to move to the next frame\n",
    "        ret1, frame1 = vid.read()\n",
    "        if not ret1:\n",
    "            break\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "        mask2 = np.zeros_like(frame1)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c16f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 3\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     18\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 19\u001b[0m points2, status, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[0;32m     20\u001b[0m     gray1, gray, points1, \u001b[38;5;28;01mNone\u001b[39;00m, winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     21\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m)\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m newpts \u001b[38;5;241m=\u001b[39m points1[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m oldpts \u001b[38;5;241m=\u001b[39m points1[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "points1 = np.float32(points1)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    points2, status, err = cv2.calcOpticalFlowPyrLK(\n",
    "        gray1, gray, points1, None, winSize=(15, 15), maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "\n",
    "    newpts = points1[status == 1]\n",
    "    oldpts = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(newpts, oldpts)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "    elif key == ord('n'):  # Press 'n' to move to the next frame\n",
    "        ret1, frame1 = vid.read()\n",
    "        if not ret1:\n",
    "            break\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "        points1 = np.float32(points1)\n",
    "        mask2 = np.zeros_like(frame1)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a358a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 3\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     18\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 19\u001b[0m points2, status, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[0;32m     20\u001b[0m     gray1, gray, points1, \u001b[38;5;28;01mNone\u001b[39;00m, winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     21\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m)\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m newpts \u001b[38;5;241m=\u001b[39m points2[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m oldpts \u001b[38;5;241m=\u001b[39m points1[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "points1 = np.float32(points1)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    points2, status, err = cv2.calcOpticalFlowPyrLK(\n",
    "        gray1, gray, points1, None, winSize=(15, 15), maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "\n",
    "    newpts = points2[status == 1]\n",
    "    oldpts = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(newpts, oldpts)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "    elif key == ord('n'):  # Press 'n' to move to the next frame\n",
    "        ret1, frame1 = vid.read()\n",
    "        if not ret1:\n",
    "            break\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "        points1 = np.float32(points1)\n",
    "        mask2 = np.zeros_like(frame1)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfa3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 3\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     18\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 19\u001b[0m points2, status, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[0;32m     20\u001b[0m     gray1, gray, points1, \u001b[38;5;28;01mNone\u001b[39;00m, winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     21\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m)\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m good_new \u001b[38;5;241m=\u001b[39m points2[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m good_old \u001b[38;5;241m=\u001b[39m points1[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "points1 = np.float32(points1)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    points2, status, err = cv2.calcOpticalFlowPyrLK(\n",
    "        gray1, gray, points1, None, winSize=(15, 15), maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "\n",
    "    good_new = points2[status == 1]\n",
    "    good_old = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "    elif key == ord('n'):  # Press 'n' to move to the next frame\n",
    "        ret1, frame1 = vid.read()\n",
    "        if not ret1:\n",
    "            break\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "        points1 = np.float32(points1)\n",
    "        mask2 = np.zeros_like(frame1)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152a657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 4\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     18\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 19\u001b[0m points2, status, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[0;32m     20\u001b[0m     gray1, gray, points1, \u001b[38;5;28;01mNone\u001b[39;00m, winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     21\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m)\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m good_new \u001b[38;5;241m=\u001b[39m points2[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     25\u001b[0m good_old \u001b[38;5;241m=\u001b[39m points1[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - prevPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'prevPts'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "points1 = np.float32(points1)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    points2, status, err = cv2.calcOpticalFlowPyrLK(\n",
    "        gray1, gray, points1, None, winSize=(15, 15), maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "\n",
    "    good_new = points2[status == 1]\n",
    "    good_old = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "    # Update the previous points for the next iteration\n",
    "    points1 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441e6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - nextPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'nextPts'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m points2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(points2)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate optical flow\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m points1, status, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[0;32m     25\u001b[0m     gray1, gray, points1, points2, winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     26\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m)\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Filter only valid points\u001b[39;00m\n\u001b[0;32m     30\u001b[0m good_new \u001b[38;5;241m=\u001b[39m points2[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowPyrLK'\n> Overload resolution failed:\n>  - nextPts is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'nextPts'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find good features in the current frame\n",
    "    points2 = cv2.goodFeaturesToTrack(gray, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "    points2 = np.float32(points2)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    points1, status, err = cv2.calcOpticalFlowPyrLK(\n",
    "        gray1, gray, points1, points2, winSize=(15, 15), maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "\n",
    "    # Filter only valid points\n",
    "    good_new = points2[status == 1]\n",
    "    good_old = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1783a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Find good features in the current frame\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m points2, _, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgoodFeaturesToTrack(gray, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, maxCorners\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, qualityLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, minDistance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, blockSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     21\u001b[0m points2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(points2)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate optical flow\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find good features in the current frame\n",
    "    points2, _, _ = cv2.goodFeaturesToTrack(gray, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "    points2 = np.float32(points2)\n",
    "\n",
    "    # Calculate optical flow\n",
    "    points1, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "        gray1, gray, points1, points2, winSize=(15, 15), maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "\n",
    "    # Filter only valid points\n",
    "    good_new = points2[status == 1]\n",
    "    good_old = points1[status == 1]\n",
    "\n",
    "    for x, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()  # 2D->1D Array\n",
    "        c, d = old.ravel()\n",
    "        mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    image = cv2.add(frame, mask2)\n",
    "    cv2.imshow(\"Frame\", image)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8841a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 3\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\video\\src\\lkpyramid.cpp:1260: error: (-215:Assertion failed) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function 'cv::`anonymous-namespace'::SparsePyrLKOpticalFlowImpl::calc'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m points2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32(corners)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate optical flow\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m points1, status, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[0;32m     27\u001b[0m     gray1, gray, points1, points2, winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m), maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     28\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m)\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Filter only valid points\u001b[39;00m\n\u001b[0;32m     32\u001b[0m good_new \u001b[38;5;241m=\u001b[39m points2[status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\video\\src\\lkpyramid.cpp:1260: error: (-215:Assertion failed) (npoints = prevPtsMat.checkVector(2, CV_32F, true)) >= 0 in function 'cv::`anonymous-namespace'::SparsePyrLKOpticalFlowImpl::calc'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning1.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find good features in the current frame\n",
    "    corners = cv2.goodFeaturesToTrack(gray, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "\n",
    "    if corners is not None and len(corners) > 0:\n",
    "        points2 = np.float32(corners)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        points1, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "            gray1, gray, points1, points2, winSize=(15, 15), maxLevel=2,\n",
    "            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "        )\n",
    "\n",
    "        # Filter only valid points\n",
    "        good_new = points2[status == 1]\n",
    "        good_old = points1[status == 1]\n",
    "\n",
    "        for x, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()  # 2D->1D Array\n",
    "            c, d = old.ravel()\n",
    "            mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "            frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "        image = cv2.add(frame, mask2)\n",
    "        cv2.imshow(\"Frame\", image)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # Press 'Esc' to exit\n",
    "            break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ae10e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the starting frame: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "frameS = int(input(\"Enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "points1 = cv2.goodFeaturesToTrack(gray1, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "mask2 = np.zeros_like(frame1)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find good features in the current frame\n",
    "    corners = cv2.goodFeaturesToTrack(gray, mask=None, maxCorners=100, qualityLevel=0.5, minDistance=10, blockSize=10)\n",
    "\n",
    "    if corners is not None and len(corners) > 0:\n",
    "        points2 = np.float32(corners)\n",
    "\n",
    "        # Calculate optical flow only if points1 is not empty\n",
    "        if points1 is not None and len(points1) > 0:\n",
    "            points1, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                gray1, gray, points1, points2, winSize=(15, 15), maxLevel=2,\n",
    "                criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "            )\n",
    "\n",
    "            # Filter only valid points\n",
    "            good_new = points2[status == 1]\n",
    "            good_old = points1[status == 1]\n",
    "\n",
    "            for x, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel()  # 2D->1D Array\n",
    "                c, d = old.ravel()\n",
    "                mask2 = cv2.line(mask2, (int(a), int(b)), (int(c), int(d)), (0, 255, 255), 4)\n",
    "                frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "            image = cv2.add(frame, mask2)\n",
    "            cv2.imshow(\"Frame\", image)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == 27:  # Press 'Esc' to exit\n",
    "                break\n",
    "\n",
    "            # Update points1 only when new points are found\n",
    "            points1 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959e5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 640, 3)\n",
      "(426, 640, 3)\n",
      "(426, 640, 3)\n",
      "(426, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "#lk=dict()\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "#print(points1)\n",
    "\n",
    "mask2=np.zeros_like(frame1)\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "    gray1=gray.copy()\n",
    "    points1=newpts.reshape(-1,1,2)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89add53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "x,y,h,w=200,200,100,100\n",
    "roi=(x,y,w,h)\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "ret1, frame1 = vid.read()\n",
    "frame_roi=frame1[y:y+h,x:x+w]\n",
    "hsv=cv2.cvtColor(frame_roi,cv2.COLOR_BGR2HSV)\n",
    "hist=cv2.calcHist([hsv],[0],None,[180],[0,180])\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    hsv_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    dst=cv2.calcBackProject([hsv_frame],[0],hist,[0,180],1)\n",
    "    outp,rei=cv2.meanShift(dst,roi,criteria)\n",
    "    x,y,w,h=roi\n",
    "    result=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    cv2.imshow(\"Meanshift\",result)\n",
    "    cv2.waitKey(0)\n",
    "    vid.release()\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "x,y,h,w=200,200,100,100\n",
    "roi=(x,y,w,h)\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "ret1, frame1 = vid.read()\n",
    "frame_roi=frame1[y:y+h,x:x+w]\n",
    "hsv=cv2.cvtColor(frame_roi,cv2.COLOR_BGR2HSV)\n",
    "hist=cv2.calcHist([hsv],[0],None,[180],[0,180])\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    hsv_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    dst=cv2.calcBackProject([hsv_frame],[0],hist,[0,180],1)\n",
    "    outp,rei=cv2.CamShift(dst,roi,criteria)\n",
    "    points=cv2.boxPoints(outp).astype(int)\n",
    "    result=cv2.polylines(frame,[points],True,(255,0,0),2)\n",
    "    cv2.imshow(\"Camshift\",result)\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361b30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=12, detectShadows=False)\n",
    "count=0\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    count+=1\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fg_mask)\n",
    "    if count > 50:\n",
    "        break\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46371567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "\n",
    "# Adjust the parameters based on your video characteristics\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=20, detectShadows=False)\n",
    "\n",
    "count = 0\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "    # Use morphological operations to clean up the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Display the original frame and the foreground mask\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fg_mask)\n",
    "\n",
    "    if count > 50:\n",
    "        break\n",
    "\n",
    "    # Adjust the waitKey value to control the playback speed\n",
    "    cv2.waitKey(0)  # 30 milliseconds per frame\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bbcdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\output_blurred_video.mp4\")\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=16, detectShadows=True)\n",
    "count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fg_mask)\n",
    "\n",
    "    if count > 50:\n",
    "        break\n",
    "\n",
    "    # Replace cv2.waitKey(0) with cv2.waitKey(1) to wait for 1 millisecond between frames\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c3d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Load the video\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\Pictures\\\\samplevideo.mp4\")\n",
    "\n",
    "# Create a folder named 'sampletest' to save faces\n",
    "output_folder = 'sampletest'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Parameters for GrabCut\n",
    "rect = (50, 50, 400, 400)  # Initial rectangle for GrabCut, adjust as needed\n",
    "bgd_model = np.zeros((1, 65), np.float64)\n",
    "fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "face_count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Crop the face region\n",
    "        face_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Apply GrabCut to separate foreground and background\n",
    "        mask = np.zeros_like(face_roi)\n",
    "        cv2.grabCut(face_roi, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "        # Modify the mask to get binary mask for the foreground\n",
    "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "        # Apply the binary mask to the face region\n",
    "        result = face_roi * mask2[:, :, np.newaxis]\n",
    "\n",
    "        # Save the individual faces to the 'sampletest' folder\n",
    "        face_count += 1\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"face_{face_count}.png\"), result)\n",
    "\n",
    "    # Display the frame with rectangles around faces\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d11c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "# Load the video\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\Pictures\\\\samplevideo.mp4\")\n",
    "\n",
    "# Create a folder named 'sampletest' to save faces\n",
    "output_folder = 'sampletest'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Parameters for GrabCut\n",
    "rect = (50, 50, 400, 400)  # Initial rectangle for GrabCut, adjust as needed\n",
    "bgd_model = np.zeros((1, 65), np.float64)\n",
    "fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "face_count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Crop the face region\n",
    "        face_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Save the individual faces to the 'sampletest' folder\n",
    "        face_count += 1\n",
    "        face_filename = os.path.join(output_folder, f\"face_{face_count}.png\")\n",
    "        cv2.imwrite(face_filename, face_roi)\n",
    "\n",
    "    # Display the frame with rectangles around faces\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342f0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the video\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\Pictures\\\\samplevideo.mp4\")\n",
    "\n",
    "# Create a folder named 'sampletest' to save faces\n",
    "output_folder = 'sampletest'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Background subtraction parameters\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=100, detectShadows=False)\n",
    "\n",
    "face_count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Crop the face region\n",
    "        face_roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Apply background subtraction mask to isolate the face\n",
    "        face_masked = cv2.bitwise_and(face_roi, face_roi, mask=fg_mask[y:y + h, x:x + w])\n",
    "\n",
    "        # Save the individual faces to the 'sampletest' folder\n",
    "        face_count += 1\n",
    "        face_filename = os.path.join(output_folder, f\"face_{face_count}.png\")\n",
    "        cv2.imwrite(face_filename, face_masked)\n",
    "\n",
    "    # Display the frame with rectangles around faces\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e324b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
